{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvxKlFv+5GcsAqX1n6ozAg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52097/Generative_AI_2025/blob/main/2303A52105_Week06_Assignment_6_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment-6.1"
      ],
      "metadata": {
        "id": "6oFq8lntKZmp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY8rKKr8KLGo",
        "outputId": "5bbe74a9-4536-43dd-d547-4b226b8be77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 12189939269632.0000 - mse: 12189939269632.0000 - val_loss: 8101491638272.0000 - val_mse: 8101491638272.0000\n",
            "Epoch 2/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4498908512256.0000 - mse: 4498908512256.0000 - val_loss: 6775744495616.0000 - val_mse: 6775744495616.0000\n",
            "Epoch 3/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3807097389056.0000 - mse: 3807097389056.0000 - val_loss: 5891605135360.0000 - val_mse: 5891605135360.0000\n",
            "Epoch 4/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3498984341504.0000 - mse: 3498984341504.0000 - val_loss: 5488799383552.0000 - val_mse: 5488799383552.0000\n",
            "Epoch 5/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3114240573440.0000 - mse: 3114240573440.0000 - val_loss: 5178314457088.0000 - val_mse: 5178314457088.0000\n",
            "Epoch 6/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3039553650688.0000 - mse: 3039553650688.0000 - val_loss: 5026555101184.0000 - val_mse: 5026555101184.0000\n",
            "Epoch 7/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3371808587776.0000 - mse: 3371808587776.0000 - val_loss: 5405909975040.0000 - val_mse: 5405909975040.0000\n",
            "Epoch 8/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2933459779584.0000 - mse: 2933459779584.0000 - val_loss: 4934799982592.0000 - val_mse: 4934799982592.0000\n",
            "Epoch 9/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2866275155968.0000 - mse: 2866275155968.0000 - val_loss: 4842111631360.0000 - val_mse: 4842111631360.0000\n",
            "Epoch 10/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3045143085056.0000 - mse: 3045143085056.0000 - val_loss: 5000624865280.0000 - val_mse: 5000624865280.0000\n",
            "Epoch 11/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2924885835776.0000 - mse: 2924885835776.0000 - val_loss: 4852540243968.0000 - val_mse: 4852540243968.0000\n",
            "Epoch 12/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3290139197440.0000 - mse: 3290139197440.0000 - val_loss: 4741046206464.0000 - val_mse: 4741046206464.0000\n",
            "Epoch 13/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2759556333568.0000 - mse: 2759556333568.0000 - val_loss: 4900863868928.0000 - val_mse: 4900863868928.0000\n",
            "Epoch 14/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3238850461696.0000 - mse: 3238850461696.0000 - val_loss: 4833434664960.0000 - val_mse: 4833434664960.0000\n",
            "Epoch 15/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2989174030336.0000 - mse: 2989174030336.0000 - val_loss: 4698526973952.0000 - val_mse: 4698526973952.0000\n",
            "Epoch 16/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2983546322944.0000 - mse: 2983546322944.0000 - val_loss: 4694799810560.0000 - val_mse: 4694799810560.0000\n",
            "Epoch 17/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3109352374272.0000 - mse: 3109352374272.0000 - val_loss: 4760159125504.0000 - val_mse: 4760159125504.0000\n",
            "Epoch 18/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2821159124992.0000 - mse: 2821159124992.0000 - val_loss: 4823483678720.0000 - val_mse: 4823483678720.0000\n",
            "Epoch 19/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2861766541312.0000 - mse: 2861766541312.0000 - val_loss: 4755673317376.0000 - val_mse: 4755673317376.0000\n",
            "Epoch 20/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2768772268032.0000 - mse: 2768772268032.0000 - val_loss: 4659530432512.0000 - val_mse: 4659530432512.0000\n",
            "Epoch 21/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3396943740928.0000 - mse: 3396943740928.0000 - val_loss: 4869971771392.0000 - val_mse: 4869971771392.0000\n",
            "Epoch 22/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2928331456512.0000 - mse: 2928331456512.0000 - val_loss: 4811532009472.0000 - val_mse: 4811532009472.0000\n",
            "Epoch 23/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3132291284992.0000 - mse: 3132291284992.0000 - val_loss: 4646268043264.0000 - val_mse: 4646268043264.0000\n",
            "Epoch 24/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2949174525952.0000 - mse: 2949174525952.0000 - val_loss: 5020214886400.0000 - val_mse: 5020214886400.0000\n",
            "Epoch 25/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2648262836224.0000 - mse: 2648262836224.0000 - val_loss: 4845880737792.0000 - val_mse: 4845880737792.0000\n",
            "Epoch 26/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3227791392768.0000 - mse: 3227791392768.0000 - val_loss: 4631813947392.0000 - val_mse: 4631813947392.0000\n",
            "Epoch 27/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2624620331008.0000 - mse: 2624620331008.0000 - val_loss: 4786371952640.0000 - val_mse: 4786371952640.0000\n",
            "Epoch 28/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2964384907264.0000 - mse: 2964384907264.0000 - val_loss: 5103050293248.0000 - val_mse: 5103050293248.0000\n",
            "Epoch 29/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2911432867840.0000 - mse: 2911432867840.0000 - val_loss: 4680228798464.0000 - val_mse: 4680228798464.0000\n",
            "Epoch 30/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2806215344128.0000 - mse: 2806215344128.0000 - val_loss: 4684459802624.0000 - val_mse: 4684459278336.0000\n",
            "Epoch 31/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2922744643584.0000 - mse: 2922744643584.0000 - val_loss: 4636435546112.0000 - val_mse: 4636435546112.0000\n",
            "Epoch 32/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2767718711296.0000 - mse: 2767718711296.0000 - val_loss: 5233155506176.0000 - val_mse: 5233155506176.0000\n",
            "Epoch 33/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2767932096512.0000 - mse: 2767932096512.0000 - val_loss: 4834854436864.0000 - val_mse: 4834854436864.0000\n",
            "Epoch 34/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3089068982272.0000 - mse: 3089068982272.0000 - val_loss: 4663683842048.0000 - val_mse: 4663683842048.0000\n",
            "Epoch 35/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3010438627328.0000 - mse: 3010438627328.0000 - val_loss: 4629371289600.0000 - val_mse: 4629371289600.0000\n",
            "Epoch 36/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2867222020096.0000 - mse: 2867222020096.0000 - val_loss: 4831584976896.0000 - val_mse: 4831584976896.0000\n",
            "Epoch 37/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2513657397248.0000 - mse: 2513657397248.0000 - val_loss: 4610039218176.0000 - val_mse: 4610039218176.0000\n",
            "Epoch 38/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3024970579968.0000 - mse: 3024970579968.0000 - val_loss: 4670123671552.0000 - val_mse: 4670123671552.0000\n",
            "Epoch 39/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3079776501760.0000 - mse: 3079776501760.0000 - val_loss: 4717725876224.0000 - val_mse: 4717725876224.0000\n",
            "Epoch 40/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3262630330368.0000 - mse: 3262630330368.0000 - val_loss: 4689598873600.0000 - val_mse: 4689598873600.0000\n",
            "Epoch 41/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2873298518016.0000 - mse: 2873298518016.0000 - val_loss: 4706879406080.0000 - val_mse: 4706879406080.0000\n",
            "Epoch 42/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2870041640960.0000 - mse: 2870041640960.0000 - val_loss: 4592987799552.0000 - val_mse: 4592987799552.0000\n",
            "Epoch 43/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2648473337856.0000 - mse: 2648473337856.0000 - val_loss: 4605230448640.0000 - val_mse: 4605230448640.0000\n",
            "Epoch 44/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3247388229632.0000 - mse: 3247388229632.0000 - val_loss: 4810886610944.0000 - val_mse: 4810886610944.0000\n",
            "Epoch 45/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2506249469952.0000 - mse: 2506249469952.0000 - val_loss: 4585358884864.0000 - val_mse: 4585358884864.0000\n",
            "Epoch 46/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2743439196160.0000 - mse: 2743439196160.0000 - val_loss: 4588310102016.0000 - val_mse: 4588310102016.0000\n",
            "Epoch 47/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3030512566272.0000 - mse: 3030512566272.0000 - val_loss: 4592986226688.0000 - val_mse: 4592986226688.0000\n",
            "Epoch 48/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2918456492032.0000 - mse: 2918456492032.0000 - val_loss: 4661464006656.0000 - val_mse: 4661464006656.0000\n",
            "Epoch 49/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2864479469568.0000 - mse: 2864479469568.0000 - val_loss: 4674559148032.0000 - val_mse: 4674559148032.0000\n",
            "Epoch 50/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3175988592640.0000 - mse: 3175988592640.0000 - val_loss: 4654988001280.0000 - val_mse: 4654988001280.0000\n",
            "Epoch 51/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2651571879936.0000 - mse: 2651571879936.0000 - val_loss: 5111907090432.0000 - val_mse: 5111907090432.0000\n",
            "Epoch 52/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2889381052416.0000 - mse: 2889381052416.0000 - val_loss: 4654631485440.0000 - val_mse: 4654631485440.0000\n",
            "Epoch 53/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2758972801024.0000 - mse: 2758972801024.0000 - val_loss: 4644011507712.0000 - val_mse: 4644011507712.0000\n",
            "Epoch 54/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3115181408256.0000 - mse: 3115181408256.0000 - val_loss: 4588470534144.0000 - val_mse: 4588470534144.0000\n",
            "Epoch 55/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2873050267648.0000 - mse: 2873050267648.0000 - val_loss: 5026183380992.0000 - val_mse: 5026183380992.0000\n",
            "Epoch 56/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2858790944768.0000 - mse: 2858790944768.0000 - val_loss: 4841137504256.0000 - val_mse: 4841137504256.0000\n",
            "Epoch 57/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2662528450560.0000 - mse: 2662528450560.0000 - val_loss: 4568841715712.0000 - val_mse: 4568841715712.0000\n",
            "Epoch 58/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2700349276160.0000 - mse: 2700349276160.0000 - val_loss: 4762959872000.0000 - val_mse: 4762959872000.0000\n",
            "Epoch 59/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2422410838016.0000 - mse: 2422410838016.0000 - val_loss: 4690398412800.0000 - val_mse: 4690398412800.0000\n",
            "Epoch 60/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3059130564608.0000 - mse: 3059130564608.0000 - val_loss: 4851521028096.0000 - val_mse: 4851521028096.0000\n",
            "Epoch 61/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2997021835264.0000 - mse: 2997021835264.0000 - val_loss: 4603996798976.0000 - val_mse: 4603996798976.0000\n",
            "Epoch 62/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2607322497024.0000 - mse: 2607322497024.0000 - val_loss: 4629469331456.0000 - val_mse: 4629469331456.0000\n",
            "Epoch 63/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2710001942528.0000 - mse: 2710001942528.0000 - val_loss: 5300268040192.0000 - val_mse: 5300268040192.0000\n",
            "Epoch 64/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2881797750784.0000 - mse: 2881797750784.0000 - val_loss: 4805535727616.0000 - val_mse: 4805535727616.0000\n",
            "Epoch 65/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3051638489088.0000 - mse: 3051638489088.0000 - val_loss: 4687412592640.0000 - val_mse: 4687412592640.0000\n",
            "Epoch 66/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2744263376896.0000 - mse: 2744263376896.0000 - val_loss: 4583793885184.0000 - val_mse: 4583793885184.0000\n",
            "Epoch 67/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2916433264640.0000 - mse: 2916433264640.0000 - val_loss: 4791153459200.0000 - val_mse: 4791153459200.0000\n",
            "Epoch 68/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3297091256320.0000 - mse: 3297091256320.0000 - val_loss: 5011698352128.0000 - val_mse: 5011698352128.0000\n",
            "Epoch 69/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2644872265728.0000 - mse: 2644872265728.0000 - val_loss: 4966776832000.0000 - val_mse: 4966776832000.0000\n",
            "Epoch 70/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3447477239808.0000 - mse: 3447477239808.0000 - val_loss: 4573242589184.0000 - val_mse: 4573242589184.0000\n",
            "Epoch 71/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2463989497856.0000 - mse: 2463989497856.0000 - val_loss: 4705643134976.0000 - val_mse: 4705643134976.0000\n",
            "Epoch 72/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2788495458304.0000 - mse: 2788495458304.0000 - val_loss: 4571878391808.0000 - val_mse: 4571878391808.0000\n",
            "Epoch 73/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2908130115584.0000 - mse: 2908130115584.0000 - val_loss: 4843413962752.0000 - val_mse: 4843413962752.0000\n",
            "Epoch 74/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2692528734208.0000 - mse: 2692528734208.0000 - val_loss: 4725002993664.0000 - val_mse: 4725002993664.0000\n",
            "Epoch 75/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3364687446016.0000 - mse: 3364687446016.0000 - val_loss: 4697540788224.0000 - val_mse: 4697540788224.0000\n",
            "Epoch 76/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3104285655040.0000 - mse: 3104285655040.0000 - val_loss: 4556217909248.0000 - val_mse: 4556217909248.0000\n",
            "Epoch 77/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2731552538624.0000 - mse: 2731552538624.0000 - val_loss: 4582408716288.0000 - val_mse: 4582408716288.0000\n",
            "Epoch 78/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2416116498432.0000 - mse: 2416116498432.0000 - val_loss: 4656951459840.0000 - val_mse: 4656951459840.0000\n",
            "Epoch 79/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3111319502848.0000 - mse: 3111319502848.0000 - val_loss: 4914873368576.0000 - val_mse: 4914873368576.0000\n",
            "Epoch 80/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3203296133120.0000 - mse: 3203296133120.0000 - val_loss: 4681541615616.0000 - val_mse: 4681541615616.0000\n",
            "Epoch 81/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2574493679616.0000 - mse: 2574493679616.0000 - val_loss: 4551032700928.0000 - val_mse: 4551032700928.0000\n",
            "Epoch 82/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2957091012608.0000 - mse: 2957091012608.0000 - val_loss: 4654261862400.0000 - val_mse: 4654261862400.0000\n",
            "Epoch 83/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2821780930560.0000 - mse: 2821780930560.0000 - val_loss: 4550669893632.0000 - val_mse: 4550669893632.0000\n",
            "Epoch 84/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2869731786752.0000 - mse: 2869731786752.0000 - val_loss: 4820458536960.0000 - val_mse: 4820458536960.0000\n",
            "Epoch 85/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3095168024576.0000 - mse: 3095168024576.0000 - val_loss: 4570939916288.0000 - val_mse: 4570939392000.0000\n",
            "Epoch 86/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2823498760192.0000 - mse: 2823498760192.0000 - val_loss: 4655251718144.0000 - val_mse: 4655251718144.0000\n",
            "Epoch 87/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2734057586688.0000 - mse: 2734057586688.0000 - val_loss: 4726081978368.0000 - val_mse: 4726081978368.0000\n",
            "Epoch 88/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2865479548928.0000 - mse: 2865479548928.0000 - val_loss: 5137869832192.0000 - val_mse: 5137869832192.0000\n",
            "Epoch 89/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2861656965120.0000 - mse: 2861656965120.0000 - val_loss: 4643288514560.0000 - val_mse: 4643288514560.0000\n",
            "Epoch 90/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3241474260992.0000 - mse: 3241474260992.0000 - val_loss: 4838579503104.0000 - val_mse: 4838579503104.0000\n",
            "Epoch 91/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2874598490112.0000 - mse: 2874598490112.0000 - val_loss: 4697417056256.0000 - val_mse: 4697417056256.0000\n",
            "Epoch 92/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3040641810432.0000 - mse: 3040641810432.0000 - val_loss: 4888882839552.0000 - val_mse: 4888882839552.0000\n",
            "Epoch 93/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2597112512512.0000 - mse: 2597112512512.0000 - val_loss: 4557046284288.0000 - val_mse: 4557046284288.0000\n",
            "Epoch 94/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2708876820480.0000 - mse: 2708876820480.0000 - val_loss: 4617041084416.0000 - val_mse: 4617041084416.0000\n",
            "Epoch 95/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2570625220608.0000 - mse: 2570625220608.0000 - val_loss: 4615344488448.0000 - val_mse: 4615344488448.0000\n",
            "Epoch 96/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2695969112064.0000 - mse: 2695969112064.0000 - val_loss: 4540517580800.0000 - val_mse: 4540517580800.0000\n",
            "Epoch 97/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2769155784704.0000 - mse: 2769155784704.0000 - val_loss: 4678910738432.0000 - val_mse: 4678910738432.0000\n",
            "Epoch 98/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2760519188480.0000 - mse: 2760519188480.0000 - val_loss: 4598888660992.0000 - val_mse: 4598888660992.0000\n",
            "Epoch 99/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2705624137728.0000 - mse: 2705624137728.0000 - val_loss: 4547155591168.0000 - val_mse: 4547155591168.0000\n",
            "Epoch 100/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2879983190016.0000 - mse: 2879983190016.0000 - val_loss: 4543509692416.0000 - val_mse: 4543509692416.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MSE: 2882787344384.0\n",
            "Testing MSE: 4543509692416.0\n",
            "Enter feature values separated by space: 1 2 3 4 5 6 7 8 9 10 11 12 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "Predicted Housing Price: 4720543.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load dataset\n",
        "data_url = \"/content/Housing.csv\"\n",
        "df = pd.read_csv(data_url)\n",
        "categorical_features = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus']\n",
        "\n",
        "df = pd.get_dummies(df, columns=categorical_features, drop_first=True) # drop_first to avoid multicollinearity\n",
        "\n",
        "X = df.drop('price', axis=1).values\n",
        "y = df['price'].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# Build the ANN model\n",
        "model = Sequential([\n",
        "    Dense(15, activation='tanh', input_shape=(X_train.shape[1],)),\n",
        "    Dense(20, activation='tanh'),\n",
        "    Dense(15, activation='tanh'),\n",
        "    Dense(1, activation='linear')  # Output layer with linear activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(), metrics=['mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate model performance\n",
        "train_mse = model.evaluate(X_train, y_train, verbose=0)[1]\n",
        "test_mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Training MSE: {train_mse}\")\n",
        "print(f\"Testing MSE: {test_mse}\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"housing_price_model.h5\")\n",
        "\n",
        "# Load and deploy model\n",
        "def predict_price(features):\n",
        "    model = load_model(\"housing_price_model.h5\")\n",
        "    features = scaler.transform([features])\n",
        "    prediction = model.predict(features)\n",
        "    return prediction[0, 0]\n",
        "\n",
        "# Example user input\n",
        "user_input = list(map(float, input(\"Enter feature values separated by space: \").split()))\n",
        "price_prediction = predict_price(user_input)\n",
        "print(f\"Predicted Housing Price: {price_prediction}\")"
      ]
    }
  ]
}